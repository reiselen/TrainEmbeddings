{
    "input_dir": "../data/",
    "output_dir": "../models/",
    "#train_size_init": 100,
    "tuning_settings": {
        "tuning_data_dir": "/media/ctext/2TB_SSD/ERE/TrainLabellers/data/Universal",
        "threads": 8,
        "max_lines": 1000000,
        "num": 20,
        "cpu": 8,
        "gpu": 4
    },
    "languages": ["ve", "xh", "zu", "nr", "nso", "ss", "st", "tn", "ts", "af"],
    "algorithms": ["w2v-s", "w2v-c", "glove", "fasttext-s", "fasttext-c", "flair-f", "flair-b"],
    "w2v-s": {
        "vector_size": {"choice": [100, 200, 300, 400, 500, 600] },
        "window": { "choice": [2, 5, 10] },
        "min_count": { "choice": [2, 5, 10, 25] },
        "workers": 2,
        "epochs": 15,
        "sg": 1,
        "hs": 1,
        "negative": 0,
        "ns_exponent": { "quniform": [0.05, 1.0, 0.001] },
        "alpha": 1,
        "min_alpha":  0.00001,
        "seed": null,
        "max_vocab_size": null,
        "max_final_vocab": null,
        "sample": 0,
        "compute_loss": false
    },
    "w2v-c": {
        "vector_size": {"choice": [100, 200, 300, 400, 500, 600] },
        "window": { "choice": [2, 5, 10] },
        "min_count": { "choice": [2, 5, 10, 25] },
        "workers": 4,
        "epochs": 15,
        "sg": 0,
        "hs": 1,
        "negative": 0,
        "ns_exponent": { "quniform": [0.05, 1.0, 0.00001] },
        "alpha": 1,
        "min_alpha":  0.00001,
        "seed": null,
        "max_vocab_size": null,
        "max_final_vocab": null,
        "sample": 0,
        "compute_loss": false
    },
    "glove": {
        "verbose": 2,
        "memory": 4.0,
        "vocab_min_count": { "choice": [2, 5, 10, 25] },
        "vector_size": {"choice": [100, 200, 300, 400, 500, 600] },
        "max_iter": 20,
        "window_size": {"choice": [10, 20, 30]},
        "binary": 2,
        "num_threads": 4,
        "x_max": 10
    },
    "fasttext-s": {
        "model": "skipgram",
        "lr": { "quniform": [0.05, 0.2, 0.00001] },
        "dim": { "choice": [100, 200, 300, 400, 500, 600] },
        "ws": 5,
        "epochs": 15,
        "minCount": 5,
        "minCountLabel": 0,
        "minn": { "choice": [2, 3] },
        "maxn": { "choice": [4, 5, 6] },
        "neg": 5,
        "wordNgrams": 1,
        "loss": "ns",
        "bucket": 2000000,
        "thread": 4,
        "lrUpdateRate": 100,
        "t": 1e-4,
        "#t": {"qloguniform": [1e-4, 1e-1, 5e-5] },
        "verbose": 2,
        "pretrainedVectors": "",
        "seed": 0
    },
    "fasttext-c": {
        "model": "cbow",
        "lr": { "quniform": [0.05, 0.2, 0.00001] },
        "dim": { "choice": [100, 200, 300, 400, 500, 600] },
        "ws": 5,
        "epochs": 15,
        "minCount": 5,
        "minCountLabel": 0,
        "minn": { "choice": [2, 3] },
        "maxn": { "choice": [4, 5, 6] },
        "neg": 5,
        "wordNgrams": 1,
        "loss": "ns",
        "bucket": 2000000,
        "thread": 2,
        "lrUpdateRate": 100,
        "t": 1e-4,
        "#t": {"qloguniform": [1e-4, 1e-1, 5e-5] },
        "verbose": 2,
        "pretrainedVectors": "",
        "seed": 0
    },
    "flair-f": {
        "temp_file_sent_size": 100000,
        "hidden_size": {"choice": [512, 768, 1024, 2048]},
        "nlayers": { "choice": [1,2,3]},
        "sequence_length": {"choice": [150, 200, 250, 300]},
        "mini_batch_size": 64,
        "learning_rate": 10,
        "epochs": { "choice": [5,10,15,20]},
        "is_forward_lm": true,
        "character_level": true,
        "pretrained_model": null
    },
    "flair-b": {
        "temp_file_sent_size": 100000,
        "hidden_size": {"choice": [512, 768, 1024, 2048]},
        "nlayers": { "choice": [1, 2, 3]},
        "sequence_length": {"choice": [150, 200, 250, 300]},
        "mini_batch_size": 64,
        "learning_rate": 10,
        "epochs": { "choice": [5, 10, 15,20]},
        "is_forward_lm": false,
        "character_level": true,
        "pretrained_model": null
    },
    "elmo":{
        "#comment": "https://github.com/allenai/allennlp-models/blob/main/training_config/",
        "config_file": "./trainers/configs/bidirectional_language_model.jsonnet"
    },
    "roberta": {
        "roberta_config": {
            "vocab_size":10000,
            "max_position_embeddings":512,
            "hidden_size":768,
            "num_attention_heads":{ "choice": [2, 3, 6, 12]},
            "num_hidden_layers": { "choice": [2, 3, 6, 12]},
            "type_vocab_size": { "choice": [2, 3, 6, 12]}
        },
        "epochs": 5,
        "model": null,
        "lines_per_instances": 50000
    }
}
